# .aliases

# profile
alias vb='vi ~/.bashrc'
alias vbp='vi ~/.bash_profile'
alias vz='vi ~/.zshrc'
alias reload="exec $SHELL -l"

# list stuff
alias ls='ls --color'
alias l='ls -lFh'
alias ltr='ls -lFhtr'
alias ltrt='ls -lFhtr | tail'
alias la='ls -lAFh'
alias ld='ls -ldh */'

# misc
alias grep='grep --color'
alias ag='alias | grep'
alias clear='clear -x' # Clear the screen but keep the terminal's scrollback buffer
alias cp='cp -i'
alias dmesg='dmesg --color --ctime' # use `journalctl --dmesg` instead
alias env='env | sort | grep -v ^__'
alias eg='env | sort | grep'
alias ff='fastfetch'
alias db='databricks'
alias dns-flush='resolvectl flush-caches'
alias dns-stats='resolvectl statistics'
alias dt='date +%Y-%m-%dT%H:%M:%S.%3N%z' # iso 8601-compliant/platform agnostic
alias dtu='echo -e "local : $(date +%Y-%m-%dT%H:%M:%S.%3N%z)\nutc   : $(date -u +%Y-%m-%dT%H:%M:%S.%3N%z)"' # show current and utc timestamps
alias dud1='du -h -d 1 . 2>/dev/null | sort --human-numeric-sort'
alias jobs='jobs -l'
alias less='less -I'
alias llast='less $(ls -1rt|tail -n1)'
alias mv='mv -i'
alias mem='free -m -t'
alias nv='nvim'
alias path='echo -e ${PATH//:/\\n}'
alias rc='echo $?'
alias rm='rm -i'
alias timer='echo "Timer started. Stop with Ctrl-D." && date && time cat && date'

# history
alias h='history'
alias hg='history | grep'

# network
alias port='netstat -tulanp'
#sudo systemd-resolve --statistics # view dns cache information (debian)
#sudo systemd-resolve --flush-caches # flush dns cache

# terraform
alias tf='terraform'
alias tfa='terraform apply'
alias tfo='terraform output'
alias tfd='terraform destroy'

# shortcuts
alias cmt='cd ~/tmp'
alias cst='cd /tmp'
alias cdl='cd ~/Downloads'
alias ..='cd ..'
alias ...='cd ../..'

# platform-agnostic clipboard copy/paste
if [ $(uname -s) = 'Linux' ]; then
    alias cbc='xclip -selection clipboard'
    alias cbp='xclip -selection clipboard -o'
elif [ $(uname -s) = 'Darwin' ]; then
    alias cbc='pbcopy'
    alias cbp='pbpaste'
fi

# vs code
if [ $(uname -s) = 'Linux' ]; then
    alias code="flatpak run com.visualstudio.code"
fi

# for when tree is not installed
alias treea="find . -print | sed -e 's;[^/]*/;|____;g;s;____|; |;g'"
alias treed="find . -type d -print | sed -e 's;[^/]*/;|____;g;s;____|; |;g'"

# python
alias ipython='ipython --TerminalInteractiveShell.editing_mode=vi --colors="Linux"'
alias jupyter-lab='jupyter-lab --ip=localhost'
alias mkvenv='python -m venv .venv && source .venv/bin/activate'
alias sva='source .venv/bin/activate'

# git
alias ga='git add'
alias gb='git branch'
alias gco='git checkout'
alias gc='git commit'
alias gcm='git commit -m'
alias gcf='git config --list'
alias gcl='git clone --recurse-submodules'
alias gig='git config --global core.excludesFile' # global .gitinore
alias gd='git diff'
alias gdc='git diff --cached'
alias gdcw='git diff --cached --word-diff'
alias gds='git diff --staged'
alias gpl='git pull'
alias gplo='git pull origin'
alias gps='git push'
alias gpsup='git push --set-upstream origin $(git branch --show-current)'
alias gpso='git push origin'
alias gpristine='git reset --hard && git clean -dfx'
alias grv='git remote -v'
alias gs='git status'
alias gss='git status --short'
alias gst='git stash'
alias gstall='git stash --all'
alias gsw='git switch'
alias gsc='git switch -c'
alias gwa='git worktree add' # git worktree add ../feature-branch-1 feature-1
alias gwl='git worktree list' # git worktree add ../feature-branch-2 feature-2
alias gwr='git worktree remove' # git worktree add ../hotfix hotfix/urgent-bug

# docker
alias docker='podman'
alias dc='docker container'
alias di='docker image'
alias dinfo='docker info'
alias dp='docker pull'
alias dri='docker run -it --rm'
alias ds='docker service'

# aws
alias aws='docker run --network host --rm -it -v ~/.aws:/root/.aws amazon/aws-cli'
# aws cli / non-interactive
alias awsnint='docker run --rm -it --volume ~/.aws:/root/.aws amazon/aws-cli'
# aws cli / interactive
alias awsint='docker run --network host --rm -it -v ~/.aws:/root/.aws amazon/aws-cli --cli-auto-prompt'

# k8s
alias k='kubectl'
alias kd='kubectl describe'
alias kdel='kubectl delete'
alias kg='kubectl get'
alias kgp='kubectl get pods'
alias kl='kubectl logs'
alias klf='kubectl logs -f' # follow
alias ks='kubectl stop'

# bat - https://github.com/sharkdp/bat
alias b='bat --style=plain'                             # no line numbers
alias bp='bat --style=plain --paging=never'             # no line numbers, no paging
alias bn='bat --number'                                 # show line numbers
alias bnp='bat --number --paging=never'                 # show line numbers, no paging
alias blp='bat --number --language=log --paging=never'  # show line numbers, no paging, logs

# pyenv
#alias pyei='pyenv install'          # install python version e.g. 3.10.1
#alias pyeil='pyenv install --list'  # list all available installable versions
#alias pyeg='pyenv global'           # select globally for your user account
#alias pyel='pyenv local'            # automatically select whenever you are in the current directory (or its subdirectories)
#alias pyes='pyenv shell'            # select just for current shell session
#alias pyeu='pyenv update'           # update pyenv versions
#alias pyev='pyenv versions'         # list installed python versions

# rye
#alias rf='rye fetch'             # install a specific python version
#alias rp='rye pin'               # pin a specific version
#alias rtl='rye toolchain list'   # list all installed python versions
#alias rtld='rye toolchain list --include-downloadable'  # list all available python versions
#alias rtr='rye toolchain remove' # remove an installed rye toolchain

# uv
alias uvip='uv init --python'
alias uvpi='uv python install'                # install a specific python version
alias uvpl='uv python list'                   # list installed and available python versions
alias uvpli='uv python list --only-installed' # list installed python versions
alias uvpipi='uv pip install'

# start spark shell
alias start_ps='spark_version=3.1.2 && hadoop_version=3.2 && install_dir=~/tools && export SPARK_HOME=${install_dir}/spark-${spark_version}-bin-hadoop${hadoop_version} && $SPARK_HOME/bin/pyspark' # pyspark shell
alias start_ss='spark_version=3.1.2 && hadoop_version=3.2 && install_dir=~/tools && export SPARK_HOME=${install_dir}/spark-${spark_version}-bin-hadoop${hadoop_version} && $SPARK_HOME/bin/spark-shell' # spark (scala) shell
