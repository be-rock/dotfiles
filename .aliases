# .aliases

# profile
alias vb='vi ~/.bashrc'
alias vbp='vi ~/.bash_profile'
alias vz='vi ~/.zshrc'
alias reload="exec $SHELL -l"

# list stuff
alias ls='ls --color'
alias l='ls -lFh'
alias ltr='ls -lFhtr'
alias ltrt='ls -lFhtr | tail'
alias la='ls -lAFh'
alias ld='ls -ldh */'

# misc
alias grep='grep --color'
alias ag='alias | grep'
alias eg='env | sort | grep'
alias hg='history | grep'
alias h='history'
alias dt='date +%FT%T%z' # iso 8601-compliant/platform agnostic
alias dttz='echo -e "local : $(date +%FT%T%z)\nutc   : $(date -u +%FT%T%z)"' # show current and utc timestamps
alias dud1='du -h -d 1 . 2>/dev/null | sort --human-numeric-sort'
alias jobs='jobs -l'
alias env='env | sort'
alias less='less -I'
alias llast='less $(ls -1rt|tail -n1)'
alias rm='rm -i'
alias cp='cp -i'
alias mv='mv -i'
alias rc='echo $?'
alias mem='free -m -t'
alias path='echo -e ${PATH//:/\\n}'
alias dmesg='dmesg --color --ctime'
alias timer='echo "Timer started. Stop with Ctrl-D." && date && time cat && date'

# network
alias port='netstat -tulanp'
#sudo systemd-resolve --statistics # view dns cache information (debian)
#sudo systemd-resolve --flush-caches # flush dns cache

# terraform
alias tf='terraform'
alias tfa='terraform apply'
alias tfo='terraform output'
alias tfd='terraform destroy'

# shortcuts
alias cmt='cd $HOME/tmp'
alias cst='cd /tmp'

# platform-agnostic clipboard copy/paste
if [ $(uname -s) = 'Linux' ]; then
    alias cbc='xclip -selection clipboard'
    alias cbp='xclip -selection clipboard -o'
elif [ $(uname -s) = 'Darwin' ]; then
    alias cbc='pbcopy'
    alias cbp='pbpaste'
fi

# for when tree is not installed
alias treea="find . -print | sed -e 's;[^/]*/;|____;g;s;____|; |;g'"
alias treed="find . -type d -print | sed -e 's;[^/]*/;|____;g;s;____|; |;g'"

# python
alias ccn='conda create --name'
alias cea='conda activate'
alias ced='conda deactivate'
alias cie='conda info --envs'
alias cl='conda list'
alias ci='conda install'
alias crn='conda remove --force --all --yes --name'
alias ipython='ipython --TerminalInteractiveShell.editing_mode=vi --colors="Linux"'
alias jupyter-lab='jupyter-lab --ip=localhost'

# git
alias ga='git add'
alias gb='git branch'
alias gco='git checkout'
alias gc='git commit'
alias gcf='git config --list'
alias gcm='git commit -m'
alias gd='git diff'
alias gdc='git diff --cached'
alias gdcw='git diff --cached --word-diff'
alias gds='git diff --staged'
alias gig='git config --global core.excludesFile' # global .gitinore
alias gpl='git pull'
alias gplo='git pull origin'
alias gps='git push'
alias gpso='git push origin'
alias gs='git status'
alias gst='git stash --all'
alias gss='git status --short'
alias gst='git stash'
alias gsta='git stash --all'
alias gpristine='git reset --hard && git clean -dfx'

# docker
alias di='docker image'
alias dc='docker container'
alias ds='docker service'
alias dinfo='docker info'

# k8s
alias k='kubectl'
alias kd='kubectl describe'
alias kdel='kubectl delete'
alias kg='kubectl get'
alias kgp='kubectl get pods'
alias kl='kubectl logs'
alias klf='kubectl logs -f' # follow
alias ks='kubectl stop'

# bat - https://github.com/sharkdp/bat
alias b='bat -p'
alias batn='bat -n'

# hadoop
alias yal='yarn application -list'
alias yas='yarn application -status'
alias hls='hadoop fs -ls'
alias hput='hadoop fs -put'
alias hget='hadoop fs -get'
alias hcp='hadoop fs -cp'
alias hcat='hadoop fs -cat'
alias hrm='hadoop fs -rm'
alias htail='hadoop fs -tail'
alias hmkdir='hadoop fs -mkdir'
alias hchmod='hadoop fs -chmod'
alias hgetfacl='hadoop fs -getfacl'
alias hdf='hadoop fs -df'
alias hdu='hadoop fs -du'
alias hmv='hadoop fs -mv'

# start spark shell
alias start_ps='spark_version=3.1.2 && hadoop_version=3.2 && install_dir=~/tools && export SPARK_HOME=${install_dir}/spark-${spark_version}-bin-hadoop${hadoop_version} && $SPARK_HOME/bin/pyspark' # pyspark shell
alias start_ss='spark_version=3.1.2 && hadoop_version=3.2 && install_dir=~/tools && export SPARK_HOME=${install_dir}/spark-${spark_version}-bin-hadoop${hadoop_version} && $SPARK_HOME/bin/spark-shell' # spark (scala) shell

